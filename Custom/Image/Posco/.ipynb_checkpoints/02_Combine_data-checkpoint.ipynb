{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62a2ae1-eee7-4df1-a72c-c7e2db7a7cc2",
   "metadata": {},
   "source": [
    "#### Option (image랑 label 이름이 달라서 바꾸기..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9694cd27-10c1-4065-84f1-22680ad8ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list = os.listdir('/root/MZC_Yubin/Object_Detection/datasets/coco128nHard-hat/images')\n",
    "# for i in img_list:\n",
    "#     os.renames(f'/root/MZC_Yubin/Object_Detection/datasets/coco128nHard-hat/images/{i}', \n",
    "#                f'/root/MZC_Yubin/Object_Detection/datasets/coco128nHard-hat/images/{\".\".join([i.split(\".\")[0], i.split(\".\")[-1]])}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186bc14-dff7-47e7-a882-5a1cca279b7f",
   "metadata": {},
   "source": [
    "## Data Info Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b21e8f5-42f2-419f-bd8d-1a7bd4d810a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 관련 버킷/폴더명 변경 후 실행\n",
    "input_json = {\n",
    "    \"s3_bucket\":\"poc-2208-posco\", ## [버킷명]\n",
    "    \"job_id\":\"version_2\", ## [버전명] Ground Truth 작업 폴더    \n",
    "    \"ground_truth_job_name\":\"gt-version-5\",  ## Ground Truth job 이름 [중복 불가]\n",
    "    \"yolo_output_dir\":\"results\" ## Ground Truth 결과 저장 위치\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c25836ea-16bf-4277-bd73-22a8b00cb8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp s3://poc-2208-posco/version_2/results/gt-version-5/annot.csv /root/MZC_Yubin/Posco/annot.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"aws s3 cp s3://{bucket}/{version}/{results}/{gt_job_name}/annot.csv /root/MZC_Yubin/Posco/annot.csv\".format(bucket = input_json['s3_bucket'], version = input_json['job_id'], \n",
    "                                                                                                                   results = input_json['yolo_output_dir'], gt_job_name = input_json['ground_truth_job_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d310e49e-e5ca-4659-bc34-42518d5c663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://poc-2208-posco/version_2/results/gt-version-5/annot.csv to ./annot.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://poc-2208-posco/version_2/results/gt-version-5/annot.csv /root/MZC_Yubin/Posco/annot.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0a62d5-5ad2-4d91-afa2-182d7085e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\") as rj:\n",
    "    data_info = json.load(rj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b659b-746d-4ef0-9adc-779eb55b586d",
   "metadata": {},
   "source": [
    "### Combine COCO datset and Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a01b17c-170d-4cae-b8cc-a0519d5fd106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "## Label Dictionary\n",
    "\n",
    "custom_list = [list(i.values())[0] for i in data_info['labels']]\n",
    "\n",
    "coco_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "             'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "             'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "             'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "             'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "             'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "             'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "             'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "             'hair drier', 'toothbrush']\n",
    "\n",
    "diff_list = list(set(custom_list) - set(coco_list))\n",
    "combine_list = coco_list.copy()\n",
    "\n",
    "for i in diff_list:\n",
    "    combine_list.append(i)\n",
    "    \n",
    "custom_dict = {string : i for i,string in enumerate(custom_list)}\n",
    "label_dict = {string : i for i,string in enumerate(combine_list)}\n",
    "\n",
    "print(custom_dict['forklift'])\n",
    "print(label_dict['forklift'])\n",
    "# print(list(label_dict.keys())[61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33a06a2a-c10a-41e7-98c2-79b193e8fbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'trailer_truck',\n",
       " 1: 'pallet&cover',\n",
       " 2: 'person',\n",
       " 3: 'car',\n",
       " 4: 'forklift',\n",
       " 5: 'pallet_truck'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom_dict\n",
    "custom_dict = dict(map(reversed,custom_dict.items()))\n",
    "## {0: 'person', 1: 'hard-hat'}\n",
    "custom_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5905060-c8a6-4271-96d9-9d0560783936",
   "metadata": {},
   "source": [
    "## S3 txt 파일 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af56801-dfba-4f75-b4da-793f5731eff7",
   "metadata": {},
   "source": [
    "### - S3 데이터 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49ac40d-8f3c-4069-901e-a4e0bffd202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "table_nm = '{}/labels'.format(input_json['job_id'])\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(input_json['s3_bucket'])\n",
    "custom_label_file = [obj.key for obj in bucket.objects.all() if obj.key.find(table_nm)>-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "637699d0-4e1a-484d-bb14-5cc0ff3b8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install smart_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "011685bc-6680-4bb2-9e7e-136fccfcf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from smart_open import smart_open\n",
    "import pandas as pd\n",
    "\n",
    "for file_name in custom_label_file:\n",
    "    lst = []\n",
    "    tmp_list = []\n",
    "\n",
    "    for line in smart_open(f\"s3://{input_json['s3_bucket']}/{file_name}\", 'rb'):\n",
    "        line = line.decode('utf8')\n",
    "        line = line.rstrip(\"\\n\")  \n",
    "        if line == \"\":\n",
    "            lst.append(tmp_list)\n",
    "            tmp_list = []\n",
    "        else:\n",
    "            tmp_list.extend(line.split())\n",
    "    if tmp_list:  # add last one\n",
    "        lst.append(tmp_list)\n",
    "\n",
    "    ## 형변환 후 DF로 변경        \n",
    "    temp_array = np.array(lst)\n",
    "    temp_df = pd.DataFrame(columns = ['label','x','y','width','height'], data = np.reshape(temp_array, (-1,5)))\n",
    "    ## 기존 Label과 index 맞추기 위해 변경\n",
    "    temp_df['label'] = temp_df['label'].astype('int')\n",
    "    temp_df['label'].replace(custom_dict, inplace =True)        \n",
    "    temp_df['label'].replace(label_dict, inplace = True)\n",
    "    temp_df['label'] = temp_df['label'].astype('str')\n",
    "\n",
    "    # 형변환\n",
    "    result_array = np.reshape(np.array(temp_df),(1,-1)).tolist()\n",
    "    result_list = []\n",
    "    for i in range(int(len(result_array[0])/5)):\n",
    "        result_list.append(' '.join(result_array[0][i*5:(i+1)*5]))\n",
    "        \n",
    "    # print(f\"s3://{input_json['s3_bucket']}/{file_name}\")\n",
    "    with smart_open(f\"s3://{input_json['s3_bucket']}/{file_name}\", 'wb') as fout:\n",
    "        for line in result_list:\n",
    "            fout.write(line.encode('utf-8'))\n",
    "            fout.write('\\n'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced87197-e48a-42d7-b69a-f022dd8c9f7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### - Local folder 데이터 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4beaedd-4bca-4559-8a80-ebfbd572f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Local Folder일 경우\n",
    "# import os\n",
    "# from os.path import isfile, join\n",
    "\n",
    "# custom_label_path = '/root/MZC_Yubin/Object_Detection/datasets/coco128nHard-hat/labels'\n",
    "# custom_label_file = [f for f in os.listdir(custom_label_path) if isfile(join(custom_label_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3708fc61-eaae-4215-bdc2-34c5d31ef1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from smart_open import smart_open\n",
    "\n",
    "# for file_name in custom_label_file:\n",
    "#     lst = []\n",
    "#     with open(f'{custom_label_path}/{file_name}') as small_pf:\n",
    "#         ## text file 엔터 없이 읽기\n",
    "#         tmp_list = []\n",
    "#         for line in small_pf:\n",
    "#             line = line.rstrip(\"\\n\")  \n",
    "#             if line == \"\":\n",
    "#                 lst.append(tmp_list)\n",
    "#                 tmp_list = []\n",
    "#             else:\n",
    "#                 tmp_list.extend(line.split())\n",
    "#         if tmp_list:  # add last one\n",
    "#             lst.append(tmp_list)\n",
    "\n",
    "#         ## 형변환 후 DF로 변경        \n",
    "#         temp_array = np.array(lst)\n",
    "#         temp_df = pd.DataFrame(columns = ['label','x','y','width','height'], data = np.reshape(temp_array, (-1,5)))\n",
    "#         ## 기존 Label과 index 맞추기 위해 변경\n",
    "#         temp_df['label'] = temp_df['label'].astype('int')\n",
    "#         temp_df['label'].replace(custom_dict, inplace =True)        \n",
    "#         temp_df['label'].replace(label_dict, inplace = True)\n",
    "#         temp_df['label'] = temp_df['label'].astype('str')\n",
    "\n",
    "#         # 형변환\n",
    "#         result_array = np.reshape(np.array(temp_df),(1,-1)).tolist()\n",
    "#         result_list = []\n",
    "#         for i in range(int(len(result_array[0])/5)):\n",
    "#             result_list.append(' '.join(result_array[0][i*5:(i+1)*5]))\n",
    "\n",
    "#     with open(f'{custom_label_path}/{file_name}', 'w') as f:\n",
    "#         for line in result_list:\n",
    "#             f.write(line)\n",
    "#             f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec7ed7-7177-4c8f-a5cf-a9e1dd02a550",
   "metadata": {
    "tags": []
   },
   "source": [
    "### - Combine Tow Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "163e11d4-edff-492f-ad41-e65f4aefbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /root/MZC_Yubin/Object_Detection/datasets/coco128/images/train2017/* /root/MZC_Yubin/Object_Detection/datasets/coco128nHard-hat/images\n",
    "\n",
    "# !cp /root/MZC_Yubin/Object_Detection/datasets/coco128/labels/train2017/* /root/MZC_Yubin/Object_Detection/datasets/coco128nHard-hat/labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b1ced-fdb9-4cb7-af20-587b9105be48",
   "metadata": {},
   "source": [
    "### - Create yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "93ad027b-5c6e-42a0-bfad-65f3db1f09df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with smart_open('s3://poc-2208-posco/input_data/custom_data.yaml', 'wb') as fout:\n",
    "#     fout.write('path : {}'.format().encode('utf-8'))\n",
    "#     fout.write('\\n'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "569f19f5-a145-4a2f-80ee-594b8b54b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://poc-2208-posco/version_2/labels/frame_001.txt to datasets/posco/labels/frame_001.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_002.txt to datasets/posco/labels/frame_002.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_005.txt to datasets/posco/labels/frame_005.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_003.txt to datasets/posco/labels/frame_003.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_011.txt to datasets/posco/labels/frame_011.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_010.txt to datasets/posco/labels/frame_010.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_007.txt to datasets/posco/labels/frame_007.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_006.txt to datasets/posco/labels/frame_006.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_009.txt to datasets/posco/labels/frame_009.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_004.txt to datasets/posco/labels/frame_004.txt\n",
      "download: s3://poc-2208-posco/version_2/labels/frame_008.txt to datasets/posco/labels/frame_008.txt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://poc-2208-posco/version_2/labels/ /root/MZC_Yubin/Posco/datasets/posco/labels --recursive  --exclude \"*.manifest\" --include \"*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f1ca096-d521-425e-9a1f-389223d74bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'pallet&cover', 'pallet_truck', 'forklift', 'trailer_truck']\n"
     ]
    }
   ],
   "source": [
    "print(len(combine_list))\n",
    "print(combine_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645d6d3f-6907-4bfa-bc28-e8c1dd8d25f5",
   "metadata": {},
   "source": [
    "### 나머진 Jupyter Notebook에서~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee54e67-0e45-467f-a1fd-c2109c9db73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'test_image'\n",
    "tag = ':latest'\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "\n",
    "byoc_image_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)\n",
    "\n",
    "byoc_image_uri\n",
    "# This should return something like\n",
    "# 111122223333.dkr.ecr.us-east-2.amazonaws.com/sagemaker-byoc-test:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e5f95-04f9-414c-b453-ff1a0ffc17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "estimator = Estimator(image_uri=byoc_image_uri,\n",
    "                      role=get_execution_role(),\n",
    "                      base_job_name='tf-custom-container-test-job',\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.g4dn.xlarge',\n",
    "                      use_spot_instances=True,\n",
    "                      max_wait=360000,\n",
    "                      max_run=100000\n",
    "                     )\n",
    "\n",
    "# start training\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faca7c2-ec03-41c6-832e-b7058e48a090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
