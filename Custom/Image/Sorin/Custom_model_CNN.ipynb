{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b125c7-da6f-47c3-a3dd-57f42961fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3530c4-255b-4f32-a068-fdab41cc41df",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd48652-0799-4362-a88f-440244af1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/root/MZC_Yubin/Sorin'\n",
    "data_dir = [os.path.join(base_dir, 'dataset_220524'), os.path.join(base_dir, 'dataset_220525')]\n",
    "# labels = ['ETC', 'Hole', 'Swell_Nomal', 'Swell_pointed','Swoot', 'Bad']\n",
    "labels = ['Hole', 'Swell_Nomal', 'Swell_pointed','Swoot']\n",
    "\n",
    "data_list = []\n",
    "label_list = []\n",
    "\n",
    "for direct in data_dir:\n",
    "    for label in labels:\n",
    "        if label != 'Bad':\n",
    "            for path in os.listdir(os.path.join(direct,f'B_{label}')):\n",
    "                if 'ipynb_checkpoints' in path:\n",
    "                    pass\n",
    "                else:\n",
    "                    data_list.append(os.path.join(direct,f'B_{label}',path))\n",
    "                    if 'Swell' in label:\n",
    "                        label_list.append('Swell')\n",
    "                    else:\n",
    "                        label_list.append(label)\n",
    "        else:\n",
    "            for path in os.listdir(os.path.join(direct, label)):\n",
    "                if 'ipynb_checkpoints' in path:\n",
    "                    pass\n",
    "                else:\n",
    "                    data_list.append(os.path.join(direct,label,path))\n",
    "                    label_list.append(label)\n",
    "                    \n",
    "# for direct in data_dir:\n",
    "#     for label in labels:\n",
    "#         if label != 'Bad':\n",
    "#             for path in os.listdir(os.path.join(direct,f'B_{label}')):\n",
    "#                 if 'ipynb_checkpoints' in path:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     data_list.append(os.path.join(direct,f'B_{label}',path))\n",
    "#                     label_list.append(label)\n",
    "#         else:\n",
    "#             for path in os.listdir(os.path.join(direct, label)):\n",
    "#                 if 'ipynb_checkpoints' in path:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     data_list.append(os.path.join(direct,label,path))\n",
    "#                     label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e7a88bc-c8b0-460e-ba73-1a0c78213d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "img_num = len(data_list)\n",
    "n = 1\n",
    "img_list = []\n",
    "for i in data_list[:img_num]:\n",
    "    if n%50 == 0:\n",
    "        print(n)\n",
    "    img = Image.open(i)\n",
    "    image_resize = img.resize((224,224))\n",
    "    img_list.append(np.array(image_resize))\n",
    "    n+=1\n",
    "    \n",
    "img_array = np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3174c109-8ff6-4113-b3c9-848fffc2c94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_label = label_list[:img_num]\n",
    "\n",
    "label_df = pd.DataFrame(columns = ['label'], data = temp_label)\n",
    "label_df = pd.get_dummies(label_df['label'])\n",
    "label_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2b290-ea2c-4182-8cbe-1e29f4f2af7f",
   "metadata": {},
   "source": [
    "## Custom Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787d4c09-c56d-4f3a-8c62-ea95c71252c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score, accuracy_score, precision_score, recall_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D, Input, Conv2DTranspose, Concatenate, Resizing, BatchNormalization\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fee5e2e-b39b-4093-a30f-8ed1eda9bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = list(set(label_list))\n",
    "\n",
    "# K.clear_session()\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(3, 32, padding = 'valid', activation = 'relu', input_shape = img_array.shape[1:]))\n",
    "# model.add(Conv2D(1, 32, padding = 'valid', activation = 'relu'))\n",
    "# model.add(MaxPooling2D(8))\n",
    "# model.add(Conv2D(1, 6, padding = 'valid', activation = 'relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(32, activation = 'relu'))\n",
    "# model.add(Dense(len(list(label_df)), activation = 'softmax'))\n",
    "# model.summary()\n",
    "\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10,restore_best_weights=True, mode='min')\n",
    "# # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "# model.fit(img_array, label_df, epochs = 100, callbacks = early_stopping_callback, batch_size = 8, validation_split=0.1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6efde4-a632-4003-80ee-9ff4174eb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f1_score(np.array(label_df).argmax(1), model.predict(img_array).argmax(1), average='macro'))\n",
    "# print(accuracy_score(np.array(label_df).argmax(1), model.predict(img_array).argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf57d1-fda7-411e-b310-a5c65b845068",
   "metadata": {},
   "source": [
    "## Check Feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465a8896-0944-415a-9b06-33d5487a27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# img = img_array[30]\n",
    "# img = img.reshape(-1,520,520,3)\n",
    "\n",
    "# temp = keras.Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "# feature_maps = temp.predict(img)\n",
    "\n",
    "# # plot all 64 maps in an 8x8 squares\n",
    "# square_x = 3\n",
    "# square_y = 1\n",
    "# ix = 1\n",
    "# plt.figure(figsize=(15, 10)) \n",
    "\n",
    "# for _ in range(square_x):\n",
    "#     for _ in range(square_y):\n",
    "#         ax = plt.subplot(square_x, square_y, ix)\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         # plot filter channel in grayscale\n",
    "#         plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "#         ix += 1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb37f2f-d95f-4325-ba26-7048006224c9",
   "metadata": {},
   "source": [
    "## ResNet 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b07b823-daa6-4986-b548-986a68c176ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet101 (Functional)       (None, 7, 7, 2048)        42658176  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 301059    \n",
      "=================================================================\n",
      "Total params: 42,959,235\n",
      "Trainable params: 42,853,891\n",
      "Non-trainable params: 105,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet import ResNet101\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "base_model = ResNet101(include_top = False, weights = \"imagenet\", input_shape = img_array.shape[1:])\n",
    "\n",
    "resize_model = Sequential()\n",
    "resize_model.add(Input(shape = img_array.shape[1:]))\n",
    "# resize_model.add(Resizing(350,350, interpolation = 'gaussian'))\n",
    "# resize_model.add(Conv2D(3,3,padding = 'same', activation = 'relu'))\n",
    "resize_model.add(base_model)\n",
    "resize_model.add(Flatten())\n",
    "resize_model.add(Dropout(0.5))\n",
    "resize_model.add(Dense(len(list(label_df)), activation = 'softmax'))\n",
    "resize_model.summary()\n",
    "\n",
    "resize_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8feaaff4-0d62-4014-8101-f4ad9d8462fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Extension horovod.torch has not been built: /usr/local/lib/python3.8/site-packages/horovod/torch/mpi_lib/_mpi_lib.cpython-38-x86_64-linux-gnu.so not found\n",
      "If this is not expected, reinstall Horovod with HOROVOD_WITH_PYTORCH=1 to debug the build error.\n",
      "Warning! MPI libs are missing, but python applications are still avaiable.\n",
      "[2022-09-15 04:42:04.537 tensorflow-2-6-gpu--ml-g4dn-xlarge-7eba0e151157af0bd8a25c896f03:48 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-09-15 04:42:04.564 tensorflow-2-6-gpu--ml-g4dn-xlarge-7eba0e151157af0bd8a25c896f03:48 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "22/22 [==============================] - 21s 278ms/step - loss: 8.1365 - accuracy: 0.5000 - val_loss: 88419648.0000 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 5.1888 - accuracy: 0.5398 - val_loss: 942844288.0000 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 10.5046 - accuracy: 0.5739 - val_loss: 235137056.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 158ms/step - loss: 7.5587 - accuracy: 0.5341 - val_loss: 79225454592.0000 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 5.2364 - accuracy: 0.5625 - val_loss: 8805287936.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 3.3482 - accuracy: 0.5739 - val_loss: 1347064704.0000 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 3.6997 - accuracy: 0.5682 - val_loss: 29088352.0000 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 1.9584 - accuracy: 0.6420 - val_loss: 547640.8125 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 159ms/step - loss: 3.5027 - accuracy: 0.5966 - val_loss: 386055.4688 - val_accuracy: 0.3000\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 4.4210 - accuracy: 0.6364 - val_loss: 700681.9375 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 10.0285 - accuracy: 0.5455 - val_loss: 25311.6992 - val_accuracy: 0.6000\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 4.3107 - accuracy: 0.5625 - val_loss: 466.3340 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 1.8218 - accuracy: 0.6591 - val_loss: 1876.7894 - val_accuracy: 0.6000\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 1.6079 - accuracy: 0.6364 - val_loss: 0.3137 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 1.7535 - accuracy: 0.6534 - val_loss: 0.8529 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 4s 160ms/step - loss: 1.4120 - accuracy: 0.7443 - val_loss: 0.9319 - val_accuracy: 0.3000\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.7023 - accuracy: 0.6932 - val_loss: 4.3400 - val_accuracy: 0.5500\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 2.6704 - accuracy: 0.6534 - val_loss: 3.7422 - val_accuracy: 0.2000\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 1.1943 - accuracy: 0.6477 - val_loss: 6.9237 - val_accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 0.5424 - accuracy: 0.6761 - val_loss: 2.3913 - val_accuracy: 0.3500\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 4s 161ms/step - loss: 2.3884 - accuracy: 0.6932 - val_loss: 1.5508 - val_accuracy: 0.3500\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 2.2197 - accuracy: 0.6648 - val_loss: 0.9120 - val_accuracy: 0.5500\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 1.7294 - accuracy: 0.7273 - val_loss: 0.7408 - val_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 2.1324 - accuracy: 0.6591 - val_loss: 0.3296 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbac22c2bb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10,restore_best_weights=True, mode='min')\n",
    "resize_model.fit(img_array, label_df, epochs = 100, callbacks = early_stopping_callback, batch_size = 8, validation_split=0.1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5348186d-6357-4d08-98de-e007fdd2727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5940717675639493\n",
      "0.6836734693877551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9, 34, 19],\n",
       "       [ 7, 42,  1],\n",
       "       [ 1,  0, 83]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f1_score(np.array(label_df).argmax(1), resize_model.predict(img_array).argmax(1), average='macro'))\n",
    "print(accuracy_score(np.array(label_df).argmax(1), resize_model.predict(img_array).argmax(1)))\n",
    "confusion_matrix(np.array(label_df).argmax(1), resize_model.predict(img_array).argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34088585-cc22-4bbc-8a92-f8d20dad7e7a",
   "metadata": {},
   "source": [
    "## VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d66b79a-43bf-42ad-aa1e-28993b85f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "module_wrapper (ModuleWrappe (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 75267     \n",
      "=================================================================\n",
      "Total params: 14,789,955\n",
      "Trainable params: 14,789,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
    "\n",
    "## VGG 모델 불러오기\n",
    "K.clear_session()\n",
    "\n",
    "base_model = VGG16(include_top = False, weights = \"imagenet\", input_shape = img_array.shape[1:])\n",
    "\n",
    "resize_model = Sequential()\n",
    "resize_model.add(Input(shape = img_array.shape[1:]))\n",
    "# resize_model.add(Resizing(350,350, interpolation = 'gaussian'))\n",
    "# resize_model.add(Conv2D(3,3,padding = 'same', activation = 'relu'))\n",
    "resize_model.add(base_model)\n",
    "resize_model.add(Flatten())\n",
    "resize_model.add(Dropout(0.5))\n",
    "resize_model.add(Dense(len(list(label_df)), activation = 'softmax'))\n",
    "resize_model.summary()\n",
    "\n",
    "resize_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2155cf8-0cfe-45c5-97b8-e5ba93459357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 16s 521ms/step - loss: 24.0662 - accuracy: 0.3864 - val_loss: 0.9243 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 1.0248 - accuracy: 0.4375 - val_loss: 0.9669 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 1.0342 - accuracy: 0.5625 - val_loss: 0.9265 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.9926 - accuracy: 0.4943 - val_loss: 0.7836 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.8218 - accuracy: 0.5625 - val_loss: 0.7751 - val_accuracy: 0.5500\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 129ms/step - loss: 0.7604 - accuracy: 0.6420 - val_loss: 0.4386 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7754 - accuracy: 0.6534 - val_loss: 0.3603 - val_accuracy: 0.9000\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7572 - accuracy: 0.6307 - val_loss: 0.4481 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6715 - accuracy: 0.6364 - val_loss: 0.5690 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7377 - accuracy: 0.6307 - val_loss: 0.5825 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6989 - accuracy: 0.6136 - val_loss: 0.3283 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7341 - accuracy: 0.6080 - val_loss: 0.7155 - val_accuracy: 0.4500\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6814 - accuracy: 0.6250 - val_loss: 1.6171 - val_accuracy: 0.2500\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6420 - accuracy: 0.6761 - val_loss: 0.6764 - val_accuracy: 0.6000\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7474 - accuracy: 0.5966 - val_loss: 0.5101 - val_accuracy: 0.9500\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.7069 - accuracy: 0.6023 - val_loss: 0.6724 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6511 - accuracy: 0.6193 - val_loss: 0.9667 - val_accuracy: 0.5500\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6169 - accuracy: 0.6591 - val_loss: 0.3787 - val_accuracy: 0.8500\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.7298 - accuracy: 0.6080 - val_loss: 0.8600 - val_accuracy: 0.5500\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.5901 - accuracy: 0.7102 - val_loss: 0.7570 - val_accuracy: 0.6500\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.6677 - accuracy: 0.6818 - val_loss: 0.3652 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba493da400>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10,restore_best_weights=True, mode='min')\n",
    "resize_model.fit(img_array, label_df, epochs = 100, callbacks = early_stopping_callback, batch_size = 8, validation_split=0.1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04d3e18c-d6ab-4ea7-864e-7dbbf71ea2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.558249346053239\n",
      "0.6938775510204082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2, 34, 26],\n",
       "       [ 0, 50,  0],\n",
       "       [ 0,  0, 84]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(f1_score(np.array(label_df).argmax(1), resize_model.predict(img_array).argmax(1), average='macro'))\n",
    "print(accuracy_score(np.array(label_df).argmax(1), resize_model.predict(img_array).argmax(1)))\n",
    "confusion_matrix(np.array(label_df).argmax(1), resize_model.predict(img_array).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "096d599a-c1c6-4edf-83b7-6a976b3f09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "\n",
    "# plt.figure(figsize = (10,10))\n",
    "# plt.imshow(img_array[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a6f7d67-9211-4173-89dc-f44e19337f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_model.predict(img_array).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c0918d9-1220-49dc-96fd-d034004106c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(label_df).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94499ac-c39d-419e-9955-d779505ae259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
